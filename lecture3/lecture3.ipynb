{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <img src=\"img/download.png\" style=\"width:75px;height:75px;\" align=\"left\">\n",
    "    <img src=\"img/logo.png\" style=\"width:75px;height:75px;\" align=\"right\">\n",
    "    <h1 align=\"center\">Deep Learning with Pytorch</h1> \n",
    "    <h3 align=\"center\"> lecture 3(Summer 2021)</h3>\n",
    "    <h5 align=\"center\">Fateme Hafezian zade [DL2021](https://fatemehafezi.gnomio.com)</h5>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"BGD\">Linear Regression 1D: Training Two Parameter Gradient Descent</a></li>\n",
    "    <li><a href=\"SGD\">Linear Regression 1D: Training Two Parameter Stochastic Gradient Descent</a></li>\n",
    "    <li><a href=\"MBGD\">Linear Regression 1D: Training Two Parameter Mini Batch Gradient Descent</a></li>\n",
    "   \n",
    "    \n",
    "</ul>\n",
    "\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1.png\" style=\"width:350px;height:300px;\">\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<img src=\"img/images.png\" style=\"width:350px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, optim\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression 1D: Training Two Parameter Gradient Descent </h1> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the f(X) with a slope of 3\n",
    "X = torch.arange(0,5, 0.1).view(-1, 1)\n",
    "f = 3 * X -1\n",
    "\n",
    "\n",
    "# Add some noise to f(X) and save it in Y\n",
    "Y = f + 3* torch.randn(X.size())\n",
    "\n",
    "\n",
    "# Create plot surface object\n",
    "\n",
    "get_surface = plot_error_surfaces(15, 13, X , Y, 30, go = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "def train_model_BGD(iter):   \n",
    "    for epock in range(iter):\n",
    "        \n",
    "        yhat = model(X)\n",
    "        loss = criterion(yhat, Y) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    return yhat    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_regression(1,1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "yhat= train_model_GD(5)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,1,1)\n",
    "plt.plot(X.detach().numpy(),yhat1.detach().numpy(), label='model_predict')\n",
    "plt.plot(X.detach().numpy(),f.detach().numpy(),\"g\",label='real_fit')\n",
    "plt.plot(X.detach().numpy(),Y.detach().numpy(),'ro', label='real_data')\n",
    "plt.title(\"gradient_decent(GD)\")\n",
    "plt.xlabel(\"x(input data)\")\n",
    "plt.ylabel(\"y(output data)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression 1D: Training Two Parameter Stochastic Gradient Descent </h1> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries we are going to use in the lab.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for ploting  \n",
    "\n",
    "class plot_error_surfaces(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):\n",
    "        W = np.linspace(-w_range, w_range, n_samples)\n",
    "        B = np.linspace(-b_range, b_range, n_samples)\n",
    "        w, b = np.meshgrid(W, B)    \n",
    "        Z = np.zeros((30, 30))\n",
    "        count1 = 0\n",
    "        self.y = Y.numpy()\n",
    "        self.x = X.numpy()\n",
    "        for w1, b1 in zip(w, b):\n",
    "            count2 = 0\n",
    "            for w2, b2 in zip(w1, b1):\n",
    "                Z[count1, count2] = np.mean((self.y - w2 * self.x + b2) ** 2)\n",
    "                count2 += 1\n",
    "            count1 += 1\n",
    "        self.Z = Z\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.W = []\n",
    "        self.B = []\n",
    "        self.LOSS = []\n",
    "        self.n = 0\n",
    "        if go == True:\n",
    "            plt.figure()\n",
    "            plt.figure(figsize = (7.5, 5))\n",
    "            plt.axes(projection = '3d').plot_surface(self.w, self.b, self.Z, rstride = 1, cstride = 1, cmap = 'viridis', edgecolor = 'none')\n",
    "            plt.title('Loss Surface')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "            plt.title('Loss Surface Contour')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.contour(self.w, self.b, self.Z)\n",
    "            plt.show()\n",
    "            \n",
    "    # Setter\n",
    "    def set_para_loss(self, model, loss):\n",
    "        self.n = self.n + 1\n",
    "        self.LOSS.append(loss)\n",
    "        self.W.append(list(model.parameters())[0].item())\n",
    "        self.B.append(list(model.parameters())[1].item())\n",
    "    \n",
    "    # Plot diagram\n",
    "    def final_plot(self): \n",
    "        ax = plt.axes(projection = '3d')\n",
    "        ax.plot_wireframe(self.w, self.b, self.Z)\n",
    "        ax.scatter(self.W, self.B, self.LOSS, c = 'r', marker = 'x', s = 200, alpha = 1)\n",
    "        plt.figure()\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.show()\n",
    "        \n",
    "    # Plot diagram    \n",
    "    def plot_ps(self,iteraction):\n",
    "        plt.subplot(121)\n",
    "        plt.ylim()\n",
    "        plt.plot(self.x, self.y, 'ro', label = \"training points\")\n",
    "        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label = \"estimated line\")\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.ylim((-10, 15))\n",
    "        plt.title('Data Space Iteration: ' + str(self.n))\n",
    "        plt.subplot(122)\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n",
    "        plt.title('Loss Surface Contour Iteration' + str(self.n) )\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        \n",
    "        plt.savefig(f'./img/BGD{iteraction}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set random seed\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Class\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "        self.f = 1 * self.x - 1\n",
    "        self.y = self.f + 0.1 * torch.randn(self.x.size())\n",
    "        self.len = self.x.shape[0]\n",
    "        \n",
    "    # Getter\n",
    "    def __getitem__(self,index):    \n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset object\n",
    "\n",
    "dataset = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model class\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build in cost function\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "\n",
    "model = linear_regression(1,1)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloader object\n",
    "\n",
    "trainloader = DataLoader(dataset = dataset, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot surface object\n",
    "\n",
    "get_surface = plot_error_surfaces(15, 13, dataset.x, dataset.y, 30, go = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "def train_model_BGD(iter):\n",
    "    for epoch in range(iter):\n",
    "        for x,y in trainloader:\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            get_surface.set_para_loss(model, loss.tolist())          \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        get_surface.plot_ps(epoch)\n",
    "        \n",
    "        \n",
    "\n",
    "start=time.time()\n",
    "train_model_BGD(10)\n",
    "End=time.time()\n",
    "Time=float(End-start)\n",
    "print(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h1 align=\"center\">compare BGD/SGD/MBGD at a glance</h1>\n",
    "    <img src=\"./img/BMS.png\" style=\"width:500px;height:300px;\" align=\"center\">            \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Batch Gradient Decent</h1>\n",
    "\n",
    "<img src=\"img/GD0.png\" style=\"width:450px;height:200px;\" align=\"left\">\n",
    "\n",
    "<img src=\"img/GD9.png\" style=\"width:450px;height:200px;\" align=\"right\">\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Mini Batch Gradient Decent</h1>\n",
    "<img src=\"img/BGD0.png\" style=\"width:450px;height:200px;\" align=\"left\">\n",
    "\n",
    "\n",
    "<img src=\"img/BGD9.png\" style=\"width:450px;height:200px;\" align=\"right\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=\"center\">Stochastic Gradient Decent</h1>\n",
    "<img src=\"img/SGDi.png\" style=\"width:450px;height:200px;\" align=\"left\">\n",
    "\n",
    "<img src=\"img/SGDii.png\" style=\"width:450px;height:200px;\" align=\"right\">\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
